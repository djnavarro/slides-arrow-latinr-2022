---
title: "A tour of the Apache Arrow ecosystem for the R community"
author: "Danielle Navarro"
subtitle: "[slides.djnavarro.net/arrow-latinr-2022](https://slides.djnavarro.net/arrow-latinr-2022)"
execute:
  echo: true
  fig-width: 10
  fig-height: 6
format: 
  revealjs:
    include-in-header:
      meta.html
    theme: dark
    css: tweaks.css
---


```{r settings}
#| include: false

# can't seem to make this work in the yaml so...
knitr::opts_chunk$set(dev.args = list(bg="#191919"))

# save the built-in output hook
hook_output <- knitr::knit_hooks$get("output")

# set a new output hook to truncate text output
knitr::knit_hooks$set(output = function(x, options) {
  if (!is.null(n <- options$out.lines)) {
    x <- xfun::split_lines(x)
    if (length(x) > n) {
      # truncate the output
      x <- c(head(x, n), "...\n")
    }
    x <- paste(x, collapse = "\n")
  }
  hook_output(x, options)
})

# global option to set output print width
options(width = 75)
```

```{r meta}
#| include: false
library(metathis)
meta() %>%
  meta_name("github-repo" = "https://github.com/djnavarro/slides-arrow-latinr-2022") %>% 
  meta_social(
    title = "A tour of the Apache Arrow ecosystem for the R community",
    url = "https://slides.djnavarro.net/arrow-latinr-2022",
    image = "https://djnavarro.net/slides-arrow-latinr-2022/img/twitter-preview.png",
    image_alt = "Image of title slide, showing the title 'A tour of the Apache Arrow ecosystem for the R community', the author 'Danielle Navarro', and the slides url: 'slides.djnavarro.net/arrow-latinr-2022'",
    og_type = "slides",
    og_author = "Danielle Navarro",
    twitter_card_type = "summary_large_image",
    twitter_creator = "@djnavarro",
    twitter_site = "@djnavarro"
  ) %>% 
  format() %>% 
  writeLines("meta.html")
```

# Sydney, Australia {.low-heading background-image="img/sydney.jpg" background-position="cover"}

There is a bridge here

<!-- image credit: me. I took this photo in 2022 -->

# Voltron Data {.high-heading background-image="img/voltrondata.png" background-position="cover"}

<!-- image credit:
copyright Voltron Data, usage for this talk is permissible
-->

Bridging languages, hardware, and people


# What is Apache Arrow?

> | 
>
> A multi-language toolbox <br> For accelerated data interchange <br> And in-memory processing

## Accelerating data interchange

![](img/data-interchange-1.png)

## Accelerating data interchange

![](img/data-interchange-2.png)

## Efficient in-memory processing

![](img/simd-1.png)

## Efficient in-memory processing

![](img/simd-2.png)

## Efficient in-memory processing

![](img/simd-3.png)

## Efficient in-memory processing

![](img/simd-4.png)

# R in the Arrow Ecosystem

## R in the Arrow Ecosystem

![](img/arrow-ecosystem-1.png)

## R in the Arrow Ecosystem

![](img/arrow-ecosystem-2.png)

## R in the Arrow Ecosystem

![](img/arrow-ecosystem-3.png)

# Arrow in the R Ecosystem

## Arrow in the R Ecosystem

- Read/write: multi-file Parquet data, csv, etc
- Compute engine: Analyze Arrow data with dplyr syntax
- Larger than memory data: Dataset interface
- Remote storage: Amazon S3, Google cloud
- Streaming Arrow data over networks with Arrow Flight
- And more...

## Arrow in the R Ecosystem

![](img/arrow-read-write.jpg)

## Arrow in the R Ecosystem

![](img/dplyr-backends-1.png)

## Arrow in the R Ecosystem

![](img/dplyr-backends-2.png)

## Arrow in the R Ecosystem

![](img/dplyr-backends-3.png)

## Arrow in the R Ecosystem

![](img/dplyr-backends-4.png)

## Packages for this talk

- Loading `tidyverse` mostly for `dplyr`
- Loading `reticulate` so we can call Python from R
- Loading `tictoc` to report timing
- Loading `arrow` for... well, Arrow!

```{r load-packages}
#| message: false
library(tidyverse)
library(reticulate)
library(arrow)
library(tictoc)
```

# Everyday data tasks with Arrow

...and 100 million rows of noise

## Read a CSV to a data frame

```{r read-csv-dataframe}
tic()
read_csv_arrow("random_data.csv") |> glimpse()
toc()
```

## Read a CSV to an Arrow table

```{r read-csv-table}
tic()
read_csv_arrow("random_data.csv", as_data_frame = FALSE) |> glimpse()
toc()
```


## Read from Parquet to a data frame

```{r read-parquet-dataframe}
tic()
read_parquet("random_data.parquet") |> glimpse()
toc()
```


## Read from Parquet to an Arrow table

```{r read-parquet-table}
tic()
read_parquet("random_data.parquet", as_data_frame = FALSE) |> glimpse()
toc()
```


## Open a multi-file dataset

```{r open-dataset}
tic()
ds <- open_dataset("random_data")
ds
toc()
```


## Use dplyr syntax with Arrow data

```{r dplyr-dataset}
tic()
ds |> 
  filter(subset == 1) |>
  glimpse()
toc()
```

- Notice that total time for `ds` is fastest
- This is because dataset only loads as needed

# Case study 1: [Visualizing a billion rows of data in less time than it takes to make a cup of coffee](https://blog.djnavarro.net/visualising-a-billion-rows/)

# New York, USA {.high-heading background-image="img/newyork.jpg" background-position="cover"}

Sometimes the data don't quite fit

<!-- image credit: me. I took this photo in 2004 -->


## Open the NYC taxi data

- NYC taxi data is a table with about 1.7B rows
- Information on taxi trips in NYC from 2009 to 2022
- Far too big to fit in memory!
- Connect using `open_dataset()`

```{r}
nyc_taxi <- open_dataset("~/Datasets/nyc-taxi/")
```

## Glimpse the NYC taxi data

```{r glimpse-nyc}
#| cache: true
glimpse(nyc_taxi)
```

## Set some handy quantities

```{r set-constants}
pixels <- 4000 # image will be 4000x4000 pixels
x0 <- -74.05   # minimum longitude to plot
y0 <- 40.6     # minimum latitude to plot
span <- 0.3    # size of the lat/long window to plot
```

## Count pickups at each image pixel

```{r count-pickups}
#| cache: true
tic()
pickup <- nyc_taxi |>
  filter(
    !is.na(pickup_longitude) & !is.na(pickup_latitude),
    pickup_longitude > x0 & pickup_longitude < x0 + span,
    pickup_latitude > y0 & pickup_latitude < y0 + span
  ) |>
  mutate(
    unit_scaled_x = (pickup_longitude - x0) / span,
    unit_scaled_y = (pickup_latitude - y0) / span,
    x = as.integer(round(pixels * unit_scaled_x)), 
    y = as.integer(round(pixels * unit_scaled_y))
  ) |>
  count(x, y, name = "pickup") |>
  collect()
toc()
```


## Glimpse the pickup counts

```{r glimpse-pickups}
glimpse(pickup)
```

## Place pickup counts on a grid

```{r grid-pickup-counts}
#| cache: true
tic()
grid <- expand_grid(x = 1:pixels, y = 1:pixels) |>
  left_join(pickup, by = c("x", "y")) |>
  mutate(pickup = replace_na(pickup,  0))
toc()
```

<br>

```{r glimpse-grid}
glimpse(grid)
```

## Coerce to matrix

```{r pickup-matrix}
pickup_grid <- matrix(
  data = grid$pickup,
  nrow = pixels,
  ncol = pixels
)

pickup_grid[2000:2009, 2000:2009]
```

## Visualization function

```{r render-image}
render_image <- function(mat, cols) {
  op <- par(mar = c(0, 0, 0, 0))
  shades <- colorRampPalette(cols)
  image(
    z = log10(t(mat + 1)),
    axes = FALSE,
    asp = 1,
    col = shades(256),
    useRaster = TRUE
  )
  par(op)
}
```

## Visualization 

```{r data-vis}
render_image(pickup_grid, cols = c("#002222", "white", "#800020"))
```




# Case study 2: [Absurdly fast data sharing between R and Python](https://blog.djnavarro.net/reticulated-arrow/)


# CÃ³rdoba, Spain {background-image="img/mezquita.jpg" background-position="cover"}

La Mezquita-Catedral is a convenient metaphor 

<!-- image source: me! I took this photo in 2004 -->




## Choose your Python environment!

My Python environments:

```{r python-setup}
conda_list()
```

<br>
An environment with `pandas` and `pyarrow` installed:

```{r use-reptilia}
use_miniconda("reptilia")
```


## Load as an R data frame 

- Data from [The Reptile Database](http://www.reptile-database.org/)
- Stored locally as a CSV file:

```{r read-taxa-dataframe}
r_taxa <- read_csv2("taxa.csv")
glimpse(r_taxa)
```

## Copy to Python panda

```{r copy-pandas}
tic()
py_taxa <- r_to_py(r_taxa)
toc()
```

<br>

- Takes about a second
- Not bad, but not ideal either

## Copy to Python panda

- Check that it worked
- Notice the formatting is panda-style!

```{r show-pandas}
py_taxa
```


## Load as an Arrow table in R

```{r read-taxa-table}
r_taxa_arrow <- read_delim_arrow(
  file = "taxa.csv", 
  delim = ";", 
  as_data_frame = FALSE
)
glimpse(r_taxa_arrow)
```


## Pass the table to Python

```{r transfer-to-python}
tic()
py_taxa_arrow <- r_to_py(r_taxa_arrow)
toc()
```

<br>

- Much faster! Takes a fraction of a second
- Foreshadowing: time is constant in the size of the table


## Pass the table to Python

- Check that it worked
- Notice the formatting is pyarrow-style!

```{r show-pyarrow-table}
py_taxa_arrow
```


## Data wrangling across languages

Compute from Python:

```{python polyglot-data-wrangle-1}
counts_arrow = r.py_taxa_arrow       \
.group_by("family")                  \
.aggregate([("taxon_id", "count")])  \
.sort_by([("family", "ascending")])
```

<br>

Inspect from R:

```{r polyglot-data-wrangle-2}
glimpse(py$counts_arrow)
```


## Setting up a simple benchmark test...

- Create synthetic "taxa" data with 100K to 10M rows
- Transfer from R to Python natively and as Arrow Tables

```{r handover-benchmark}
#| cache: true
handover_time <- function(n, arrow = FALSE) {
  data_in_r <- slice_sample(r_taxa, n = n, replace = TRUE)
  if(arrow) data_in_r <- arrow_table(data_in_r)
  tic()
  data_in_python <- r_to_py(data_in_r)
  t <- toc(quiet = TRUE)
  return(t$toc - t$tic)
}

times <- tibble(
  n = seq(100000, 10000000, length.out = 100),
  data_frame = map_dbl(n, handover_time),
  arrow_table = map_dbl(n, handover_time, arrow = TRUE),
)
```

## ... and how long does the data handover take?

```{r plot-benchmarks}
#| echo: false
times |> 
  pivot_longer(
    cols = c("data_frame", "arrow_table"), 
    names_to = "type", 
    values_to = "time"
  ) |> 
  mutate(
    type = type |> 
      factor(
        levels = c("data_frame", "arrow_table"),
        labels = c("Data Frames", "Arrow Tables")
      )
  ) |>
  ggplot(aes(n / 1000000, time)) + 
  geom_point() + 
  facet_wrap(~type) + 
  theme_bw(base_size = 24) + 
  labs(
    x = "Millons of Rows (of Taxa Data)",
    y = "Handover Time (Seconds)"
  )
```


# Case study 3: Remote data sources

# Whyalla, Australia {.high-heading background-image="img/whyalla.jpg" background-position="cover"}

Remote storage is not unfamiliar to country girls

<!-- image source:
- https://www.flickr.com/photos/82134796@N03/48766912621
- denisbin on flickr
- CC-BY-ND-2.0 licence
-->

## Amazon simple storage service (S3)

- Remote file storage service
- Fast, scalable, cheap
- Very handy if all you need is storage
- Analogous services via Google Cloud, Microsoft Azure

## Connecting to an S3 bucket

```{r connect-bucket}
#| cache: true
bucket <- s3_bucket("voltrondata-labs-datasets")
bucket$ls()
```

<br>

```{r ls-nyc-taxi}
#| cache: true
bucket$ls("nyc-taxi")
```


## Open a dataset stored in an S3 bucket

```{r open-s3-data}
#| cache: true
tic()
bucket <- s3_bucket("voltrondata-labs-datasets/nyc-taxi")
remote_taxi <- open_dataset(bucket) 
toc()
```


## Querying the remote dataset

```{r query-s3-data}
#| cache: true
tic()
result <- remote_taxi |> 
  filter(year == 2019, month == 1) |>
  summarize(
    all_trips = n(),
    shared_trips = sum(passenger_count > 1, na.rm = TRUE)
  ) |>
  mutate(pct_shared = shared_trips / all_trips * 100) |>
  collect()
toc()
```

<br>

```{r inspect-result}
#| cache: true
result
```


## But what if I need a remote server?

- Sometimes a remote filesystem like S3 isn't enough
- Sometimes you need the remote system to do computations
- If so, you may want an Arrow Flight server...

## What is Arrow Flight?

- Flight is a remote procedure call (RPC) protocol
- Flight is used to stream Arrow data over a network
- Fully supported by the Arrow C++ and Python libraries
- R support is a wrapper around the Python flight library 
- Related: Flight SQL and ADBC (not in this talk!)

## Starting the Flight server

```{r start-server}
#| eval: false
demo_server <- arrow::load_flight_server("demo_flight_server")
server <- demo_server$DemoFlightServer(port = 8089)
server$serve()
```


## Uploading data from a client machine

Connect to server:

```{r flight-connect}
client <- flight_connect(port = 8089)
```

<br>

Upload data:

```{r upload-from-client}
flight_put(client, data = airquality, path = "pollution_data")
```

<br>

Check that it worked:

```{r list-flights}
list_flights(client)
```



## What happens when `flight_put()` is called?

![](img/do_put.png)

## Downloading data to a client machine

```{r download-to-client}
flight_get(client, "pollution_data") |>
  glimpse()
```


## What happens when `flight_get()` is called?

![](img/do_get.png)



# Where do I go next?

## Resources

- [arrow-user2022.netlify.app](https://arrow-user2022.netlify.app/)
- [github.com/thisisnic/awesome-arrow-r](https://github.com/thisisnic/awesome-arrow-r)
- [blog.djnavarro.net/category/apache-arrow](https://blog.djnavarro.net/category/apache-arrow)
- [arrow.apache.org/docs/r](https://arrow.apache.org/docs/r/)
- [arrow.apache.org/cookbook/r](https://arrow.apache.org/cookbook/r/)


```{r, echo=FALSE, results='hide'}
client$do_action("shutdown")
```



